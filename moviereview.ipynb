{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "moviereview.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "P69tpbeL-J3H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import numpy\n",
        "from keras.datasets import imdb\n",
        "from matplotlib import pyplot\n",
        "# load the dataset\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data()\n",
        "X = numpy.concatenate((X_train, X_test), axis=0)\n",
        "y = numpy.concatenate((y_train, y_test), axis=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcriUP7x-KPt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "9c766fad-b02e-456e-c65b-4c3cd5b21893"
      },
      "source": [
        "# MLP for the IMDB problem\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "# load the dataset but only keep the top n words, zero the rest\n",
        "top_words = 5000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
        "max_words = 500\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_words)#padding the sequence to get same length for all the inputs <pad>\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(top_words, 32, input_length=max_words))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(250, activation='relu'))\n",
        "model.add(Dense(500, activation='relu'))\n",
        "model.add(Dense(1, activation='tanh'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=128, verbose=2)\n",
        "#valuation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
        "\n",
        "\n",
        "def predict(y):\n",
        "  y = sequence.pad_sequences(y, maxlen=max_words)\n",
        "  if(model.predict(y)>0.6):\n",
        "    return \"positive\"\n",
        "  return \"negative\"\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 16000)             0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 250)               4000250   \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 500)               125500    \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1)                 501       \n",
            "=================================================================\n",
            "Total params: 4,286,251\n",
            "Trainable params: 4,286,251\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/10\n",
            " - 35s - loss: 0.5492 - acc: 0.7235 - val_loss: 0.3198 - val_acc: 0.8674\n",
            "Epoch 2/10\n",
            " - 34s - loss: 0.2285 - acc: 0.9234 - val_loss: 0.3784 - val_acc: 0.8658\n",
            "Epoch 3/10\n",
            " - 34s - loss: 0.1891 - acc: 0.8788 - val_loss: 0.6729 - val_acc: 0.8204\n",
            "Epoch 4/10\n",
            " - 34s - loss: 0.1554 - acc: 0.8656 - val_loss: 1.1409 - val_acc: 0.6220\n",
            "Epoch 5/10\n",
            " - 34s - loss: 0.2197 - acc: 0.6444 - val_loss: 5.1288 - val_acc: 0.1964\n",
            "Epoch 6/10\n",
            " - 34s - loss: 0.3727 - acc: 0.7244 - val_loss: 0.8937 - val_acc: 0.6590\n",
            "Epoch 7/10\n",
            " - 34s - loss: 0.0794 - acc: 0.6950 - val_loss: 0.9221 - val_acc: 0.7256\n",
            "Epoch 8/10\n",
            " - 34s - loss: 0.0762 - acc: 0.6643 - val_loss: 1.3009 - val_acc: 0.5283\n",
            "Epoch 9/10\n",
            " - 34s - loss: 0.0486 - acc: 0.5642 - val_loss: 1.3796 - val_acc: 0.5171\n",
            "Epoch 10/10\n",
            " - 34s - loss: 0.0446 - acc: 0.5462 - val_loss: 1.4361 - val_acc: 0.5010\n",
            "Accuracy: 50.10%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l71Ps5kO_RcG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f739ed3-747b-4f9f-9f7a-f1ae2da74590"
      },
      "source": [
        "inp=X_test[1,:]\n",
        "print(inp.shape)\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(500,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUDFWdKGAXxl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "82a397b2-278d-4f97-c4b7-87433bd953b6"
      },
      "source": [
        "print(predict(inp.reshape(1,-1)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YexJzcNaBQN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8xNEAl7Cxxf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}